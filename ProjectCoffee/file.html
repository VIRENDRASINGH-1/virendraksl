<html>
    <head>

    </head>
    <body>
        <center>india</center>
        <center>
            <h1>i understood html basic building blocks</h1>
        </center>
        
        <h2>i understood html basic building blocks</h2>
        <h3>i understood html basic building blocks</h3>
        <h4>i understood html basic building blocks</h3>
        <h5>i understood html basic building blocks</h5>
        <h6>i understood html basic building blocks</h6>
        virendra
        <i>virendra</i>
        virendra
        <b>virendra</b>
        <strike>rohit</strike>
        <u>virat</u>
        x2
        x<sup>2</sup>
        CO<sub>2</sub>
        H<sub>2</sub>O
        <p>
             This might sound like the stuff of science fiction, but Hawking says dismissing it as such “would be a mistake, and potentially our worst mistake ever.”

             Compared to robots, we humans are pretty clunky. Limited by the slow pace of evolution, it takes us generations to iterate. Robots, on the other hand, can improve upon their own design a lot faster, and soon, they’ll probably be able to do so without our help. Hawking says this will create an “intelligence explosion” in which machines could exceed our intelligence “by more than ours exceeds that of snails.”

             A lot of people think that the threat of AI centers on it becoming malevolent rather than benevolent. Hawking disabuses us of this concern, saying that the “real risk with AI isn’t malice, but competence.” Basically, AI will be very good at accomplishing its goals; if humans get in the way, we could be in trouble.

             “You’re probably not an evil ant-hater who steps on ants out of malice, but if you’re in charge of a hydroelectric green-energy project and there’s an anthill in the region to be flooded, too bad for the ants. Let’s not place humanity in the position of those ants,” Hawking writes.

             For those still unpersuaded, he suggests a different metaphor. “Why are we so worried about AI? Surely humans are always able to pull the plug?” a hypothetical person asks him.
 
             Hawking answers: “People asked a computer, ‘Is there a God?’ And the computer said, ‘There is now,’ and fused the plug.”
        </p>
        <blockquote>    
            Hawking’s biggest warning is about the rise of artificial intelligence: It will either be the best thing that’s ever happened to us, or it will be the worst thing. If we’re not careful, it very well may be the last thing.

            Artificial intelligence holds great opportunity for humanity, encompassing everything from Google’s algorithms to self-driving cars to facial recognition software. The AI we have today, however, is still in its primitive stages. Experts worry about what will happen when that intelligence outpaces us. Or, as Hawking puts it, “Whereas the short-term impact of AI depends on who controls it, the long-term impact depends on whether it can be controlled at all.”
        </blockquote>
        <pre>
            janaganamana adhinayaka jayahe
                bharatha bhagyavidhatha
        </pre>
        <p>
        <center>
            <b>
                <i>Why do we use it?</i>
            </b>
        </center>
        
       
        <hr/>
         Stephen Hawking has a final message for humanity: If robots don’t get us, climate change will.

         Hawking, who died at age 76 of a degenerative neurological disease earlier this year, offers his parting thoughts in a posthumously published book called Brief Answers To The Big Questions, which comes out Tuesday. It’s a message worth heeding from a man who is probably the most renowned scientist since Einstein, best known for his discovery of how black holes function. Hawking’s book A Brief History of Time sold more than 10 million copies and tackled questions as big as “How did the universe begin?” and “What will happen when it ends?” in language simple enough for the average reader.
        </p>
        
        <li>cricket</li>
        <li>Football</li>
        <li>Hockey</li>

        <ol>
            <li>cricket</li>
            <li>Football</li>
            <li>Hockey</li>
        </ol>
        <ol type="i">
            <li>
                cricket
                    <ul>
                        <li>bowler</li>
                        <li>batter</li>
                        <li>keeper</li>
                    </ul>
            </li>
            <li>Football</li>
            <li>Hockey</li>
        </ol>
        <ul type="circle">
            <li>cricket</li>
            <li>Football</li>
            <li>Hockey</li>
        </ul>
        <ul type="square">
            <li>cricket</li>
            <li>Football</li>
            <li>Hockey</li>
        </ul>
        <dl>
            <dt>What is Hooke’s Law?</dt>
            <dd>
                Hooke’s law states that the strain of the material is proportional to the applied stress within the elastic limit of that material.
            </dd>
        </dl>
        <table border="2" width="50%">
            <tr>
                <td>No.</td>
                <td>Full Name</td>
                <td>Position</td>
                <td>Salary</td>
            </tr>
            <tr>
                <td>1</td>
                <td>Bill Gates</td>
                <td>Founder Microsoft</td>
                <td>$1000</td>
            </tr>
            <tr>
                <td>1</td>
                <td>Bill Gates</td>
                <td>Founder Microsoft</td>
                <td>$1000</td>
            </tr>
            <tr>
                <td>2</td>
                <td>Steve Jobs</td>
                <td>Founder Apple</td>
                <td>$1300</td>
            </tr>
            <tr>
                <td>3</td>
                <td>Mark </td>
                <td>Founder Facebook</td>
                <td>$1800</td>
            </tr>
        </table>
            <tr>
                <td>3</td>
                <td>Mark </td>
                <td>Founder Facebook</td>
                <td>$1800</td>
            </tr>
        </table>
    </body>  
</html>